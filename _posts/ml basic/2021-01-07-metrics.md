---
layout: post
title: "모델평가 지표: metrics(미완)"
date: 2021-01-07
excerpt: "모델을 평가하는 평가지표에 대해 알아보자"
tags: [ML Basic]
category: ML Basic
comments: False
use_math: true
---

학습이 끝나고 모델이 완성되면, 이제 이 모델을 평가해야할 차례이다. 여기서 모델이 완성된다는 것은 모델의 파라미터들(Weights)이 모두 결정된다는 것을 의미한다. 

따라서 학습에 의한 파라미터가 얼마나 적합한가에 대해서 검토해야할 필요가 있다. 모델평가는 다양한 지표들에 의해서 이루어지는데, 크게 classification과 regression에서의 방법으로 구분되고 classification은 정량화되지 않은 값들에 대한 평가이기에 regression대비 조금 더 복잡하다.

따라서, 우선적으로 classification에서 어떠한 metrics가 쓰이는지 Confusion Matrix를 통해 선험적으로 보고, 구체적으로 어떠한 지표들이 실질적으로 적용되는 지 검토한 후에 regression의 다양한 지표들을 살펴보자.

## 이진분류와 Confusion matrix
#### Confusion Matrix
Confusion matrix는 classification에서 모든 경우의 수를 검토한 후, 도메인에 적합하게 이들을 조합하는 기초가 된다. 아래의 그림과 같이 4가지의 항목이 존재하며 각 항목을 설명하면 다음과 같다.
* TP: 이는 실제로 참이며, 예측도 참으로 했다는 것을 의미한다.
* FP: 이는 실제로 거짓이나, 예측을 참으로 했다는 것을 의미한다.
* FN: 이는 실제로 참이지만 예측을 거짓으로 했다는 것을 의미한다.
* TN: 이는 실제로 거짓이며, 예측도 거짓으로 했다는 것을 의미한다.

![image](https://user-images.githubusercontent.com/49096513/104833717-257f0f00-58de-11eb-8a59-c6591faf8832.png)

즉, 위 그림에 따르면, 잘못 예측한 것은 FN, FP가 되며, 이들은 각각 Type2 error, Type1 error로 불리운다.
어떠한 에러가 더 치명적인지는 적용되는 도메인에 따라 극명하게 갈리기 때문에 어떠한 평가지표를 사용할까에 대해서는 신중해야한다.

이들을 비율로써 간단하게 수치화 한 Accuracy, Specificity, Precision, Recall(Sensitivity), F1-Score 등이 있다.

* Accuracy(정확도): $TP+TN \over TP+FN+FP+TN$
* Specificity(특이도): $FP \over TN + FP$
* Precision(정밀도): $TP \over TP+FP$
* Recall(재현률), Sensitivity(민감도): $TP \over TP+FN$
* F1-score: $2* {Precision * Recall \over Precision + Recall}$ (precision과 recall의 조화평균 즉, 둘중 하나가 낮다면 f1도 낮도록 조정) 

#### ROC, PR, AUC
TN과 TP를 모두 낮추면 아주 이상적인 모델이 되겠지만, 둘은 어느정도의 Trade-off를 가지고 있기에 분포가 아래의 그림과 같이 나타날 수밖에 없다.

![image](https://user-images.githubusercontent.com/49096513/104834148-ec946980-58e0-11eb-82b5-bdf357a443cd.png)

* ROC Curve: 따라서 Threshold를 움직일 때마다, TN과 TP의 값이 변하게 된다. 이러한 Threshold에 따른 곡선 즉, FP비율 대비 TP비율을 나타낸 곡선을 ROC Curve라고 하며, 이는 곡선형태를 띄게 된다. 
* ROC AUC: ROC Curve의 곡선의 휘어지는 정도는 TP와 TN의 분포에 따라 결정되는데 두 분포 사이의 거리가 가까울수록 곡선이 완만해지며, 거리가 멀수록 곡선의 휘어진 정도가 심해진다. 따라서, 이러한 휘어진 정도는 일정한 곡선에서의 밑 넓이로써 표현이 가능한데, 이를 ROC AUC라고 하며, 1이 될 수록 좋은 모델이라고 판단이 가능하다.

## 회귀에대한 지표
앞서 언급했듯, regression의 경우에는 예측값과 참값이 모두 수치적으로 주어지기 때문에, classification 대비 아주 간편하다. 

큰 관심사는 이러한 지표가 부호를 반영하는가와 이상치의 영향을 많이 받는가가 핵심이 된다.

* MAE: $\sum {(y- \hat{y}) /over n}$, 이상치에 강건하나 부호반영이 안된다.
* RMSE: ${100 \over n} \sum {(y- \hat{y}) \over y}$, zero devision error의 위험성이 있으나, 스케일 처리가 된다.
* MSE: $\sum{(y - \hat{y})^2 \over n}$, 부호반영이 되지 않고 이상치에 민감하나, 식이 간편하여 자주 쓰인다.


이제까지 다양한 지표를 살펴봤으나, 사실 현업에서는 특정한 지표가 도메인에 따라 우세하게 사용되는 경우가 다반사이다. 그러나, 이것을 알고 있는 것과 모르는 것의 차이는 분명할 것이라고 생각된다.

## Reference
* [youtube](https://www.youtube.com/watch?v=O-AhNAU6WlY)
* [fig.1](https://glassboxmedicine.com/2019/02/17/measuring-performance-the-confusion-matrix/)
* [fig.2](http://arogozhnikov.github.io/2015/10/05/roc-curve.html)
