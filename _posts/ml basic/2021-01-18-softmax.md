---
layout: post
title: "softmax: multi-classification"
date: 2021-01-18
excerpt: "다중 클래스에 대한 분류를 가능하게 하는 softmax함수를 살펴보자."
tags: [ML Basic]
category: ML Basic
comments: False
use_math: true
---

앞서 로지스틱회귀를 통해서 이진 클래스 분류를 어떻게 하는 지 살펴보았는데, 소프트맥스회귀는 다중 클래스 분류를 목적으로 한다.
가령, 특정한 개체가 A 집단인가, B 집단인가에 대한 논의는 이진 클래스 분류에 해당하고, 여기에 C 집단이 추가된다면 다중 클래스 분류에 해당한다.

## 함수에 넣기 위한 전처리
그렇다면 어떤 식으로 소프트맥스 함수의 적용이 이루어지는가?

다시 말하지만, 소프트맥스는 다중클래스 분류이다. 따라서, 범주가 K개라면 함수가 리턴하는 벡터는 K 차원이어야 한다는 것이다.

그러나, input으로는 feature의 개수만큼의 차원이 주어진다. 
즉, 개체를 특정짓는 feature가 M차원일 경우, 이것을 K차원으로 바꾸어야 한다는 것을 의미한다. 
더욱이 M차원의 feature에 대해서 K개만큼이 존재하므로, 인풋은 K x M 차원의 텐서가 된다!!!!!

따라서, 우리는 이것을 바꾸기 위해서 텐서를 입력하기전에 K차원의 벡터로 바꾸고자 (K x M)에 (M x 1)의 벡터를 행렬곱(matmul) 하여 (K x 1)의 벡터로 변환한다.

이렇게 변환된 벡터는 소프트맥스함수로 들어가게 된다.

> 참고로 1차원은 vector, 2차원은 metrix, 3차원 이상은 tensor라고 칭한다.

## 소프트맥스 함수의 이해
위 과정을 통해 인풋을 K 차원의 텐서로 만들었으면, 이를 소프트맥스 함수에 넣어주어 값들을 반환받아야 한다.

소프트맥스 함수의 식은 아래와 같은데, 이는 다중클래스 분류를 위해서 K차원의 벡터로 결과 값을 반환받고, 이 반환된 값은 특정 클래스의 확률 값이어야 한다는 것을 지킨 식이다.

$$p_i = {e^{z_i} \over \sum_{j=1}^K {e^{z_j}}}$$

위 식에서 $p_i$는 i번째 클래스가 정답일 확률이며, $z_{i}$는  i번째 원소에 해당한다.

식을 말로 풀면 모든 원소의 exponential 값 대비 특정 원소의 exponential 값이라고 할 수 있다.

## 후 처리
이렇게 나온 확률에 대한 K 차원의 벡터는 특정한 클래스라고 말하기 위해서 원핫 벡터로 변경한다. 
즉, 가장 큰 값을 참(=1)이라고 하고, 나머지 값을 거짓(=0)으로 하여 반환한다는 것이다.

## cost function
cost function은 로지스틱 회귀와 동일한 cross entorpy를 사용하여 구한다. 이에 대해서는 [다음의 문서](https://silverstar0727.github.io/ml%20basic/2021/01/05/cross_entropy/#)를 참조하라.

## Reference
* [docs](https://wikidocs.net/35476)
