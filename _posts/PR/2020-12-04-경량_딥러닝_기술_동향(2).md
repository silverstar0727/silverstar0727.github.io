---
layout: post
title: "경량 딥러닝 기술 동향(2)"
date: 2020-12-04
excerpt: "ETRI의 모델 경량화 연구결과의 내용 정리"
category: Paper Review
tags: [PR]
comments: False
use_math: true
---

## 모델 압축
#### 가중치 가지치기
작은 값을 갖는 가중치들을 0으로 만들어 네트워크의 모델 크기를 줄이는 기술이다.

![image](https://user-images.githubusercontent.com/49096513/102744779-ebcded80-439d-11eb-83d1-6abb8e711563.png)

#### 양자화 및 이진화
부동소수점을 줄이기 위해서 64비트를 8비트로 줄이는 등의 방법을 사용하는 것은 양자화이며, -1 or +1로 변환하는 것은 이진화이다.

#### 가중치 공유
저장 공간을 줄이기 위해 가중치들을 근사한 값으로 K-Mean or Gaussian Mixture Model을 사용하는 것이다.

## 지식증류
앙상블로 학습된 다수의 네트워크(전문가 모델)에서의 아웃풋인 확률값들을 확률 분포로 변환하여 작은 모델(숙련가 모델)의 학습시에 반영하는 형태로 삽입하는 것을 의미한다.

![image](https://user-images.githubusercontent.com/49096513/102745094-a827b380-439e-11eb-989f-d88b9f39f8e3.png)

## 하드웨어 가속
구글의 TPU NVIDIA의 GPU중에서도 Ampere 아키텍처를 사용하여 딥러닝 전용으로 출시된 A100, Graph Core의 IPU등이 그것에 해당한다.

## Reference
[경량 딥러닝 기술 동향](https://ettrends.etri.re.kr/ettrends/176/0905176005/34-2_40-50.pdf)
