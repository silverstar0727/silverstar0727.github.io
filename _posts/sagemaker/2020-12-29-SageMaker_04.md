---
layout: post
title: "Distributed Training"
date: 2020-12-29
excerpt: "SageMaker- Train Model with a Tensorflow - Dsitributed Training"
tags: [SageMaker]
category: SageMaker
comments: False
use_math: true
---

본 문서는 [AWS SageMaker의 official document](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow)를 토대로 작성되었습니다.

- - -

## Contents

#### Train a Model with TensorFlow
* [Prepare a Training Script](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-26-SageMaker_01.md)(완)
  * Adapting your local TensorFlow script
  * Use third-party libraries
* [Create an Estimator](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-27-SageMaker_02.md) (완)
  * Specify a Docker image using an Estimator
* [Call the fit Method](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-28-SageMaker_03.md) (완)
* [Distributed Training](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-29-SageMaker_04.md) (완)
  * Training with parameter servers
  * Training with Horovod
* [Training with Pipe Mode using PipeModeDataset](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-30-SageMaker_05.md)(완)
* Training with MKL-DNN disabled (보류...)

#### Deploy TensorFlow Serving models
* [Deploy to a SageMaker Endpoint](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-31-SageMaker_07.md) (완)
  * Deploying from an Estimator
    * What happens when deploy is called
  * Deploying directly from model artifacts
  * Making predictions against a SageMaker Endpoint
* Run a Batch Transform Job
  * Create a Transformer Object
  * Call transform
  * Batch Transform Supported Data Formats
* TensorFlow Serving Input and Output
  * Supported Formats
    * Simplified JSON Input
    * Line-delimited JSON
  * Create Python Scripts for Custom Input and Output Formats
    * How to implement the pre- and/or post-processing handler(s)
    
#### SageMaker TensorFlow Classes

#### SageMaker TensorFlow Docker containers

- - -


## Distributed Training
분산학습을 실행하기 위해서는 instance_count가 1보다 큰 숫자여야 한다. SageMaker에서는 Parameter server와 Horovod를 이용한 두 가지 분산학습 방법을 지원한다.

estimator를 생성할 때, 'distribution'을 새로운 파라미터로 추가하여 이를 이용하면 된다.

## Training with parameter servers
parameter server를 이용한 분산학습의 경우는 인스턴스를 worker와 parameter server로 나누고 이들의 역할을 job이라고 부른다.
worker들은 훈련을 담당하게 되며, parameter server는 훈련된 paramter들을 받아서 효율적인 분산학습을 하도록 돕는 역할을 한다.

SageMaker에서는 distribution의 parameter에 {'parameter_server': {'enabled': True}}를 추가함으로써 간단하게 실행할 수 있다.

~~~python
from sagemaker.tensorflow import TensorFlow

tf_estimator = TensorFlow(
    entry_point = 'tf-train.py',
    role = 'SageMakerRole',
    instance_count = 2,
    instance_type = 'ml.p2.xlarge',
    framework_version = '2.2',
    py_version = 'py37',
    distribution = {'parameter_server': {enabled = True}},
)

tf_estimator.fit('s3://bucket/path/to/training/data')
~~~

## Training with Hrorovod
Horovod를 이용한 훈련 내용은 아래 reference의 링크를 참조. 사용 방법으로는 MPI 환경설정을 하고 mpirun을 실행하여 사용하게 된다.

구체적으로는 ditribution의 파라미터에 다음의 필드를 지정하여 구성하면 된다.
* enabled(bool): True로 설정되면 MPI가 설정되고 mpirun 수행 명령을 실행하게 된다
* processes_per_host(int): 각 호스트에서 MPI를 시작해야 하는 프로세스의 개수로 앞서 instance_type에서 선택한 가용 gpu개수보다 작은 값으로 설정해야 한다.
* custom_mpi_option(str): 모든 mpirun플래그를 SageMaker에서 실행하기 위해 전달해주는 역할을 한다.

~~~python
from sagemaker.tensorflow import TensorFlow

tf_estimator = Tensorflow(
    entry_point = 'tf-train.py',
    role = 'SageMakerRole',
    instance_count = 1,
    instance_type = 'ml.p3.8xlarge',
    framework_version = '2.2',
    py_version = 'py37',
    distribution = {
        'mpi': {
            'enabled': True,
            'processes_per_host': 4,
            'custum_mpi_option': '--NCCL_DEBUG INFO',
            }})

tf_estimator.fit('s3://bucket/path/to/training/data')
~~~

## Reference
분산학습 관련 문서는 아래를 참조
* [Tensorflow Doc](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md)
* [Blog](https://excelsior-cjh.tistory.com/162)
* [horovod github](https://github.com/horovod/horovod)
* [horovod blog](https://y-rok.github.io/deep%20learning/2019/12/19/horovod-tensorflow.html)
