---
layout: post
title: "Prepare a Training Script"
date: 2020-12-26
excerpt: "SageMaker- Train Model with a Tensorflow - Prepare a Training Script"
tags: [SageMaker]
category: SageMaker
comments: False
use_math: true
---

본 문서는 [AWS SageMaker의 official document](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow)를 토대로 작성되었습니다.

전체 예제는 [mnist.py](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_training_and_serving/mnist.py)에서 볼 수 있습니다.


- - -

## Contents

#### Train a Model with TensorFlow
* [Prepare a Training Script](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-26-SageMaker_01.md)(완)
  * Adapting your local TensorFlow script
  * Use third-party libraries
* [Create an Estimator](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-27-SageMaker_02.md) (완)
  * Specify a Docker image using an Estimator
* [Call the fit Method](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-28-SageMaker_03.md) (완)
* [Distributed Training](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-29-SageMaker_04.md) (완)
  * Training with parameter servers
  * Training with Horovod
* [Training with Pipe Mode using PipeModeDataset](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-30-SageMaker_05.md)(완)
* Training with MKL-DNN disabled (보류...)

#### Deploy TensorFlow Serving models
* [Deploy to a SageMaker Endpoint](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-31-SageMaker_07.md) (완)
  * Deploying from an Estimator
    * What happens when deploy is called
  * Deploying directly from model artifacts
  * Making predictions against a SageMaker Endpoint
* Run a Batch Transform Job
  * Create a Transformer Object
  * Call transform
  * Batch Transform Supported Data Formats
* TensorFlow Serving Input and Output
  * Supported Formats
    * Simplified JSON Input
    * Line-delimited JSON
  * Create Python Scripts for Custom Input and Output Formats
    * How to implement the pre- and/or post-processing handler(s)
    
#### SageMaker TensorFlow Classes

#### SageMaker TensorFlow Docker containers

- - -


## Prepare a Traning Script
Tensorflow 모델을 학습하기 위해서는 다음의 3가지가 필요하다.
* training script에 대한 준비
* sagemaker.tensorflow.Tensorflow estimator의 생성
* estimator에서의 fit 메서드 호출

#### Useful Environment Variables
우선 training script에서 유용하게 쓰이는 환경변수에 대해서 알고 넘어갈 필요가 있다.
* SM_MODEL_DIR: str타입이며, 모델 artifact를 쓰는 로컬 경로를 나타내는 문자열이다. 
교육 이후 추론과정에서 해당 모델을 사용하기 위해 해당 위치에 업로드를 하게 된다. 
이는 model_dir의 인자와는 다른 값을 갖고, 항상 /opt/ml/model로 설정된다.
* SM_NUM_GPUS: int타입으로 가용의 GPU개수를 나타낸다.
* SM_OUTPUT_DATA_DIR: str타입이며 출력 artifact에 저장될 체크포인트 등의 파일 위치
* SM_CHANNEL_XXXX: str타입으로 입력 데이터의 위치를 나타낸다. 예를 들어 fit메서드에서 train, test 두개의 입력채널을 지정하면 SM_CHANNEL_TRAIN, SM_CHANNEL_TEST 두 개의 환경변수가 설정된다

argparse.ArgumentParser 인스턴스를 이용하여 hyperparameter를 설정한다. 이때, add_argument 메서드를 이용하고 type에는 자료형을, default에는 hyperparameter의 값을 넣는다. 이후 input 데이터와 모델 위치를 설정하는데, 이 역시 add_argument 메서드를 통해 type과 default로는 위치를 os.environ.get('SM_CHANNEL_XXXX') 형식으로 추가한다.

~~~python
import argparse
import os

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    
    # hyperparameters
    parser.add_argument('--epochs', type = int, default = 10)
    parser.add_argument('--batch_size', type = int, default = 100)
    parser.add_argument('--learning_rate', type = float, default = 0.1)
    
    # input data and model directories
    parser.add_argument('--model_dir', type = str)
    parser.add_argument('--train', type = str, default = os.environ.get('SM_CHANNEL_TRAIN'))
    parser.add_argument('--test', type = str, default = os.environ.get('SM_CHANNEL_TEST'))
    
    args, _ = parser.parse_known_args()
~~~

- - -

## Adapting your local TensorFlow script
외부에서 작성한 TF script를 SageMaker에서 활용하기 위해서 다음 세 가지를 참고하여 script를 수정하면 된다.

#### 1. --model_dir 추가
만약 --model_dir를 별도로 지정하지 않은 경우, 기본 학습작업의 bucket 아래에 모델이 훈련 후 저장된다. 추가로 파라미터 서버의 분산학습을 사용하기 위해서는 tf.estimator.train_and_valuate API를 사용하고 training 도중에 S3위치를 제공해야한다.

~~~python
mnist_classifier = tf.estimator.Estimator(model_fn = my_model_fn, model_dir = args.model.dir)
train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps = 1000)
eval_spec = tf.estimator.EvalSpec(eval_input_fn)

tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)
~~~

#### 2. 데이터 위치 load
input  채널에서 데이터를 로드해야한다. 이때, fit 메서드에서 딕셔너리 형태의 인자로 넣음으로써 실행하면 된다.

~~~python
estimator.fit({'train': 's3://my-buckeet/my-training-data',
               'eval': 's3://my-bucket/my-evaluation-data'})
~~~

training script에서는 위에서 언급한 parser인스턴스에 다음과 같이 인자를 추가해주면 된다.

~~~python
parser = argparse.ArgumentParser()
parser.add_argument('--train', type = str, defualt = os.environ.get('SM_CHANNEL_TRAIN'))
parser.add_argument('--eval', type = str, default = os.environ.get('SM_CHANNEL_EVAL'))
~~~

#### 3. 최종 모델의 저장 경로
이렇게 완성된 최종 모델은 SM_CHANNEL_MODEL_DIR의 경로로 내보내지는데 이는 /opt/ml/model의 위치이다. 따라서 훈련이 끝나면 /opt/ml/model/output_path에 업로드 된다.

- - -

## Use Third-party libraries
별도 라이브러리를 추가로 이용하는 경우 Training과 Serving에서 어떠한 방식으로 사용하는 지 버전에 따라 안내한다.

#### For Training
requirements.txt를 이용하여 적용한다.
* TF가 1.15.2 이면서 python 3.7 이거나 TF가 2.2 버전 이상인 경우
    * requirements.txt를 훈련 스크립트와 동일한 위치에 저장해야 한다.
    * Tensorflow estimator에서 반드시 source_dir 인자를 통해 해당 디렉토리를 저장해야 한다.
* TF가 1.11 부터 15.2 이거나 2.0부터 2.1까지 중 하나이고 python 3.7 또는 3.6인 경우
    * pip install -r requirements.txt를 쉘 스크립트에서 진입 포인트에 우선적으로 명령어를 집어 넣어야 한다. 그 이후 훈련 스크립트를 실행해야 한다.
    * [예제](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_script_mode_using_shell_commands/tensorflow_script_mode_using_shell_commands.ipynb)를 참고
    
#### For Serving
마찬가지로 requirements.txt를 사용하여 적용한다.
* Tf가 1.11버전 이상인 경우
    * requirements.txt 파일을 코드와 동일한 디렉토리에 저장한다.
        
> 결국 최신 버전의 경우에는 requirements.txt파일을 동일한 디렉토리에 저장하는 것으로 충분하다. 
