---
layout: post
title: "Training with Pipe Mode using PipeModeDataset"
date: 2020-12-30
excerpt: "SageMaker- Train Model with a Tensorflow - Training with Pipe Mode using PipeModeDataset"
tags: [SageMaker]
category: SageMaker
comments: False
use_math: true
---

본 문서는 [AWS SageMaker의 official document](https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#train-a-model-with-tensorflow)를 토대로 작성되었습니다.

- - -

## Contents

#### Train a Model with TensorFlow
* [Prepare a Training Script](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-26-SageMaker_01.md)(완)
  * Adapting your local TensorFlow script
  * Use third-party libraries
* [Create an Estimator](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-27-SageMaker_02.md) (완)
  * Specify a Docker image using an Estimator
* [Call the fit Method](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-28-SageMaker_03.md) (완)
* [Distributed Training](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-29-SageMaker_04.md) (완)
  * Training with parameter servers
  * Training with Horovod
* [Training with Pipe Mode using PipeModeDataset](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-30-SageMaker_05.md)(완)
* Training with MKL-DNN disabled (보류...)

#### Deploy TensorFlow Serving models
* [Deploy to a SageMaker Endpoint](https://github.com/silverstar0727/AWS-SageMaker-Docs/blob/main/sagemaker/2020-12-31-SageMaker_07.md) (완)
  * Deploying from an Estimator
    * What happens when deploy is called
  * Deploying directly from model artifacts
  * Making predictions against a SageMaker Endpoint
* Run a Batch Transform Job
  * Create a Transformer Object
  * Call transform
  * Batch Transform Supported Data Formats
* TensorFlow Serving Input and Output
  * Supported Formats
    * Simplified JSON Input
    * Line-delimited JSON
  * Create Python Scripts for Custom Input and Output Formats
    * How to implement the pre- and/or post-processing handler(s)
    
#### SageMaker TensorFlow Classes

#### SageMaker TensorFlow Docker containers

- - -


## Training with Pipe Mode using PipeModeDataset
SageMaker는 파이프 입력 모드를 이용하여 훈련 작업을 생성할 수 있다. 
파이프 입력 모드는 데이터의 빠른 다운로드 대신 훈련을 위한 인스턴스로 직접 스트리밍된다는 단점이 있다.
즉, 훈련의 작업이 더 빠르고 디스크의 공간이 더 적게 필요한 대신, 인스턴스에 대한 비용이 많이 발생할 수 있다.

SageMaker의 TensorFlow는 tf.data.Dataset 기능을 제공하는데, 이는 파이프 모드를 쉽게 활용할 수 있는 데이터 셋이다.
TFRecord가 훈련 인스턴스로 실행될 때, tf.data.Dataset를 sagemaker_tensorflow.PipeModeDataset로 바꿀 수 있다.

entry_point에 해당하는 스크립트에서 PipeMode 데이터 셋을 Dataset과 같이 사용할 수도 있다. 

~~~python
from sagemaker_tensorflow import PipeModeDataset

features = {
  'data': tf.FixedLenFeature([], tf.string),
  'labels': tf.FixedLenFeature([], tf.int64),
  }

def parse(record):
  parsed = tf.parse_single_example(record, features
  
  return ({'data': tf.decode_raw(parse['data'], tf.float64)}, parsed['labels'])
  
def train_input_fn(training_dir, hyperparameters):
  ds = PipeModeDataset(channel = 'training', record_format = 'TFRecord')
  ds = ds.repeat(20)
  ds = ds.prefetch(10)
  ds = ds.map(parse, num_parallel_calls = 10)
  ds = ds.batch(64)
  
  return ds
~~~

한편 estimator를 설정할 때는, 파이프 입력 모드로 실행하기 위해서 input_mode 필드에 'Pipe'를 넣어주어야 한다.

~~~python
from sagemaker.tensorflow import TensorFlow

tf_estimator = TensorFlow(
  entry_point = 'tf-train-with-pipemodedataset.py',
  role = 'SageMakerRole',
  training_steps = 10000,
  evaluation_steps = 100,
  instance_count = 1,
  instance_type = 'ml.p2.xlarge',
  framework_version = '1.10.0',
  py_version = 'py37',
  input_mode = 'Pipe')
  
tf_estimator.fit('s3://bucket/path/to/training/data')
~~~

TFRecord가 압축 파일로 있는 경우 Gzipped TF Rcords 위에서 훈련을 할 수 있다. 
이때는 fit메서드를 호출할 때 compression = 'Gzip'을 추가하여 준다.

~~~python
from sagemaker.tensorflow import TrainingInput

train_s3_input = TrainingInput('s3://bucket/path/to/training/data', compression = 'Gzip')
tf_estimator.fit(training_s3_input)
~~~

## Reference
[github](https://github.com/aws/sagemaker-tensorflow-extensions)


