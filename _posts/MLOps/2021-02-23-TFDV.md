---
layout: post
title: "TFDV 사용기"
date: 2021-02-23
excerpt: "TFDV에 대한 주요 내용 훑기 및 TFX에서의 위상"
tags: [MLOps]
comments: False
use_math: true
---

## TFDV Overview
TFDV는 TFX에 속해있는 데이터 검증 툴이라고 보시면 될 것 같습니다.

이제서야 사용해보는데, Azure의 ML Studio의 Designer에서 데이터를 분석한 것 같은 느낌이랄까? 아니, 사실 그것보다 더 쉽고 용이한 것 같다고 느껴집니다.

구글의 강력함이라 할 수 있는데, 이것과 연관된 솔루션이 워낙 많다보니 TFX와 결합하여 좋은 효율을 발휘하고 있기 때문입니다.
특히 TFDV는 TFX에서 파이프라인 구축의 

간단히 기능들에 대해서 살펴보자면 아래와 같은 기능이 수행 가능하다.

* 데이터에 대한 통계량 생성
* 스키마 생성
* 스키마 수동 조절
* 스키마를 기준으로 기존 데이터와 비교

그렇다면 이러한 기능들이 TFX와 어떻게 결합되는가?

이전 포스트에서 살펴본 바에 따르면 TFX의 pipeline은 아래 그림과 같이 구성이 된다.

![image](https://user-images.githubusercontent.com/49096513/108688974-dca12280-753b-11eb-9399-039e755e406e.png)

따라서 pipeline에서 schemaGen, stattisticsGen, exampleValidator와 같은 기능들을 TFDV는 효율적으로 수행이 가능하다는 것이다.

그래서 Training과 Serving의 과정을 조금 나눠서 생각해보면, Training에서는 우리가 원래부터 갖고 있는 데이터라고 가정하고 Serving에서는 새로운 데이터가 들어온다고 가정하자.

실제와 크게 다른 상황이 아니니, 신빙성 있을 것이다. 아래와 같은 순서로 TFDV가 쓰인다는 것을 잘 봐두자.

#### For Training
1. 데이터에 대한 통계량 생성
2. 통계량을 사용하여 피처에 대한 스키마를 생성
3. 시각화 후 수동으로 조절

#### For Serving
1. 새 데이터에 대한 통계량 및 스키마 생성
2. Training 스키마와 시각화 후 비교
3. 기존 데이터에서의 anomalies 검증

## TFDV 설치
Colab에서 TFDV를 실행하려면 우선 pip를 업그레이드 해야한다. 따라서 아래 명령어를 통해 업그레이드를 진행시켜주자.

~~~
!pip install pip-upgrade
~~~

그리고 여기서 조금 중요한데, 꼭 런타임을 다시시작 해야한다. pip를 적용해야하기 때문… 그 이후 아래 명령어를 통해서 tensorflow data validation을 설치하고 임포트하여 버전을 확인해주자.
~~~
!pip install -q tensorflow-data-validation

import tensorflow_data_validation as tfdv
tfdv.version.__version__
~~~

## 통계량 확인하기
설치가 끝나면 각종 통계량을 확인할 수 있는데, 아래 코드를 통해 생성하고 시각화 하여 확인이 가능하다.
~~~
# 통계량 생성
train_stats = tfdv.generate_statistics_from_csv(data_location = {INPUT_DIR})
# 시각화
tfdv.visualize_statictics(train_stats)
~~~

그럼 아래 이미지처럼 통계량을 효율적으로 확인할 수 있다. 꿀팁인데, 데이터를 두개를 넣으면 동시에 한 화면에서 확인도 가능하다.

![image](https://user-images.githubusercontent.com/49096513/108844462-83122400-761f-11eb-917f-fe86d19ba80e.png)


## 스키마 확인하기
통계량 확인 이후에 스키마도 아래 코드로 확인해보자.
~~~
# 스키마 생성
schema = tfdv.infer_schema(statistics = train_stats)
# 스키마 시각화
tfdv.display_schema(schema = schema)
~~~

그리고 스키마를 커스터마이징할 수 있는데, get_feature 메서드를 이용하자!!

## 새로운 데이터에 대한 검증
아래의 코드는 기존의 스키마와 새로운 통계량 간의 검증이 가능하다. anomalies를 잡아내 준다는 특징이 있다.
~~~
anomalies = tfdv.validate_statistics(statistics = eval_stats, schema = schema)
tfdv.display_anomalies(anomalies)
~~~


그리고 그 이후 사실 나머지들은 그냥 기존 방법론의 확장이라서 핵심적인 내용만 다뤄봤다…

자주쓸듯 싶다.

## Reference
* https://zzsza.github.io/mlops/2019/05/12/tensorflow-data-validation-basic/
* https://towardsdatascience.com/hands-on-tensorflow-data-validation-61e552f123d7
* https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines?hl=ko
